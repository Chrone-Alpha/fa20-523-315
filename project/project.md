# Project on Gesture recognition and machine learning

- [ ] progress uncluear
- [ ] learn markdown
- [ ] learn what a ulr is and how to do one in markdown
- [ ] please get write access for the other students, contact gregor or TA via piazza

Peiran Zhao, Sunny Xu, Kris Zhang,_[fa20-523-315](https://github.com/cybertraining-dsc/fa20-523-315/), [Edit](https://github.com/cybertraining-dsc/fa20-523-315/blob/master/project/project.md)

{{% pageinfo %}}

## Abstract
Since our technology is more and more advanced as time goes by, traditional human-computer interaction has become increasingly difficult to meet people's demands. In this digital era, people need faster and more efficient methods to obtain information and data. Traditional and single input and output devices are not fast and convenient enough, it also requires users to learn their own methods of use, which is extremely inefficient and completely a waste of time. Therefore, artificial intelligence comes out, and its rise has followed the changeover times, and it satisfied people's needs. At the same time, gesture is one of the most important way for human to deliver information. It is simple, efficient, convenient, and universally acceptable. Therefore, gesture recognition has become an emerging field in intelligent human-computer interaction field, with great potential and future. 

**Keywords:** gesture recognition, human, technology, future

## Table of contents
1. Introduction
2. Background 
3. Gesture recognition
4. Conclusion

## Introduction

## Background
Nowadays, people are doing more and more research on high-tech, which also makes various high-tech products appear in the society. For people, electricity is as important as water and air. It is impossible to imagine a life without electricity. We can realize that technology is changing everything about people from various aspects. People living in this high-tech era are also forced to learn and understand the usage of various high-tech products. As a representative of high technology, artificial intelligence has also attracted a lot of attention in society. Because of the emergence of artificial intelligence, people have also begun to realize that preserving the characteristics of the people is also a very important point in high technology. Therefore, scientists thought of gestures, one of the most commonly used body language.


## Gesture recognition
Gesture recognition is mainly divided into two categories, one is based on external device recognition, the specific application is data gloves, wearing it on user's hand, to obtain and analysis information through sensors. This method has obvious shortcomings, though it is accurate and has excellent response speed, but it is costly and is not good for large-scale promotion. The other one is the use of computer vision. People do not need to wear gloves. As its name implies, this method collects and analyzes information through a computer. It is convenient, comfortable, and not so limited based on external device identification. In contrast, it has greater potential and is more in line with the trend of the times. Of course, this method needs more effective and accurate algorithms to support, because the gestures made by different people at different times, in different environments and at different angles also represent different meanings. So, if we want more accurate information feedback. Then the advancement of algorithms and technology is inevitable. The development of gesture recognition is also the development of artificial intelligence, a process of the development of various algorithms from data gloves to the development of computer vision-based optical technology plays a role in promoting it.

## Conclusion







## References

[^1]: Srilatha, Poluka, and Tiruveedhula Saranya. “Advancements in Gesture Recognition Technology.” IOSR Journal of VLSI and Signal Processing, vol. 4, no. 4, 2014, pp. 01–07, iosrjournals.org/iosr-jvlsi/papers/vol4-issue4/Version-1/A04410107.pdf, 10.9790/4200-04410107. Accessed 25 Oct. 2020.
